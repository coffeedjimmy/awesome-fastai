{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"02_fully_connected.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8Oalz_MfA62w","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hAOco_L_t5DJ","colab_type":"text"},"source":["## Colab 사용자용"]},{"cell_type":"code","metadata":{"id":"lnAUy-3Pt1Jk","colab_type":"code","outputId":"22e84dd2-4ff9-4d65-9d4c-78e2fa6c8456","executionInfo":{"status":"ok","timestamp":1566922267200,"user_tz":-540,"elapsed":28179,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","# repo에 있는 exp 폴더를 불러오자.\n","# /content 에 파일을 두면 colab 에서 인식된다.\n","# 원본 파일 경로는 자신의 드라이브에 맞게 설정\n","!cp -r /gdrive/\"My Drive\"/develop/course-v3-master/course-v3-master/nbs/dl2/exp /content"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eK_gKmT1A62y","colab_type":"text"},"source":["## The forward and backward passes"]},{"cell_type":"code","metadata":{"id":"gAsOthTcA620","colab_type":"code","colab":{}},"source":["#export\n","from exp.nb_01 import *\n","\n","def get_data():\n","    path = datasets.download_data(MNIST_URL, ext='.gz')\n","    with gzip.open(path, 'rb') as f:\n","        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n","    return map(tensor, (x_train,y_train,x_valid,y_valid))\n","\n","def normalize(x, m, s): return (x-m)/s"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_QmnuwNA622","colab_type":"code","colab":{}},"source":["x_train,y_train,x_valid,y_valid = get_data() # MNIST 데이터를 가져온다. (이전 강의에서 다룸)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgB7JAfHA624","colab_type":"code","outputId":"e5a73956-590a-4230-bff0-ebf172c99986","executionInfo":{"status":"ok","timestamp":1566925822185,"user_tz":-540,"elapsed":8315,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_mean,train_std = x_train.mean(),x_train.std()\n","train_mean,train_std # 평균과 분산을 확인해본다."],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.1304), tensor(0.3073))"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"aR6VDeOUA626","colab_type":"code","colab":{}},"source":["x_train = normalize(x_train, train_mean, train_std) # 데이터를 정규화하자. (가우시안)\n","# NB: Use training, not validation mean for validation set\n","x_valid = normalize(x_valid, train_mean, train_std)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxmcRvwqA628","colab_type":"code","outputId":"182fda39-52ac-49e1-e4ee-203b26799ef5","executionInfo":{"status":"ok","timestamp":1566925822186,"user_tz":-540,"elapsed":7980,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_mean,train_std = x_train.mean(),x_train.std()\n","train_mean,train_std # 정규분포를 따른다."],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.0001), tensor(1.))"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"TboPy20QA62_","colab_type":"code","colab":{}},"source":["#export\n","def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJojBiOfA63B","colab_type":"code","colab":{}},"source":["test_near_zero(x_train.mean())\n","test_near_zero(1-x_train.std())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVGTT0TyA63D","colab_type":"code","outputId":"4aaca1ee-0a1e-490c-f01a-471ac8b93a26","executionInfo":{"status":"ok","timestamp":1566925822187,"user_tz":-540,"elapsed":7493,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["n,m = x_train.shape\n","c = y_train.max()+1\n","n,m,c # 학습셋 개수, 인풋차원, 클래스 개수"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 784, tensor(10))"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"sgC7yV6jA63F","colab_type":"text"},"source":["## Foundations version"]},{"cell_type":"markdown","metadata":{"id":"0xnJOZL2A63G","colab_type":"text"},"source":["### Basic architecture"]},{"cell_type":"code","metadata":{"id":"M6DWxNfPA63H","colab_type":"code","colab":{}},"source":["# 히든 레이어의 뉴럴 수\n","nh = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"89yPj_f5A63K","colab_type":"code","colab":{}},"source":["# kaiming init / he init 을 단순화 하였다.\n","w1 = torch.randn(m,nh)/math.sqrt(m)     # 1st 레이어 (784, 50)\n","b1 = torch.zeros(nh)\n","\n","w2 = torch.randn(nh,1)/math.sqrt(nh)    # 2nd 레이어 (50, 1) \n","b2 = torch.zeros(1)                     # 여기서 아웃풋이 10 이 아니라 1인것은 단순화하기 위해서다. 추후에 변경함"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqmcId_hA63M","colab_type":"code","colab":{}},"source":["test_near_zero(w1.mean())\n","test_near_zero(w1.std()-1/math.sqrt(m))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qMe9rmTA63O","colab_type":"code","outputId":"e6d6a6f6-d896-4d83-9286-da21745420ef","executionInfo":{"status":"ok","timestamp":1566925822188,"user_tz":-540,"elapsed":6228,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# This should be ~ (0,1) (mean,std)...\n","x_valid.mean(),x_valid.std()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-0.0057), tensor(0.9924))"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"VETzosNgA63S","colab_type":"code","colab":{}},"source":["def lin(x, w, b): return x@w + b    # 간단하게 구현한 Linear Layer 계산"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFWUKPSMA63U","colab_type":"code","colab":{}},"source":["t = lin(x_valid, w1, b1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mOQi9MH0A63W","colab_type":"code","outputId":"69b2de5c-e7b2-45e1-e36d-0fdf55e5946b","executionInfo":{"status":"ok","timestamp":1566925822189,"user_tz":-540,"elapsed":5719,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# kaiming init을 사용했기에 다음과 같은 평균과 표준편차를 구할 수 있었다.\n","t.mean(),t.std() # 거의 정규 분포를 따르는 값"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-0.0278), tensor(0.9444))"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ENpsI6VqA63Y","colab_type":"code","colab":{}},"source":["def relu(x): return x.clamp_min(0.)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3WthtVt3A63a","colab_type":"code","colab":{}},"source":["t = relu(lin(x_valid, w1, b1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFMSeNZJA63d","colab_type":"code","outputId":"ce526e04-8afd-44ba-fd54-97fa9e6af721","executionInfo":{"status":"ok","timestamp":1566925822191,"user_tz":-540,"elapsed":5208,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["t.mean(),t.std()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.3603), tensor(0.5420))"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"I4P7NaBBxmn2","colab_type":"text"},"source":["relu를 지나고 나니 위에서 처럼 (mean, std) = (0, 1) 이 아니다.\n","\n","왜그럴까? \n","\n","relu를 지나면서 0보다 작은 수는 모두 0으로 올라왔기 때문이다.\n","(8강 1:31:40 참고)"]},{"cell_type":"markdown","metadata":{"id":"RaVMmFDUA63i","colab_type":"text"},"source":["From pytorch docs: `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n","\n","$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n","\n","This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)"]},{"cell_type":"code","metadata":{"id":"RrY1r-n2A63k","colab_type":"code","colab":{}},"source":["# kaiming init / he init for relu\n","# relu를 위해 초기화 방법을 위의 식으로 바꿔보자\n","# w1 = torch.randn(m,nh)/math.sqrt(m)   # previous\n","w1 = torch.randn(m,nh)*math.sqrt(2/m)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YteFzNIaA63m","colab_type":"code","outputId":"afb2d4d2-53d3-40b8-882f-238dde3197b5","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925822191,"user_tz":-540,"elapsed":4542,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["w1.mean(),w1.std()  # 표준편차가 1이 아닌 0.05로 작아짐"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.0003), tensor(0.0505))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"sHEX0zA4A63o","colab_type":"code","outputId":"4c2a5294-893b-4d74-e9aa-5f76860f3771","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925822192,"user_tz":-540,"elapsed":4330,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["t = relu(lin(x_valid, w1, b1))\n","t.mean(),t.std()    # 대신 relu를 지나고 나서는 표준편차가 1에 가까워짐"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.5851), tensor(0.8287))"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"1wLt2sej4Q0C","colab_type":"text"},"source":["### torch.nn 의 init 모듈을 사용해보자"]},{"cell_type":"code","metadata":{"id":"aSfujs1iA63q","colab_type":"code","colab":{}},"source":["#export\n","from torch.nn import init"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_1bDwazA63s","colab_type":"code","colab":{}},"source":["w1 = torch.zeros(m,nh)\n","init.kaiming_normal_(w1, mode='fan_out')    # init 모듈 내부에 구현되어있는 kaiming init\n","t = relu(lin(x_valid, w1, b1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-b3ZsywA63t","colab_type":"code","colab":{}},"source":["'''\n","mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\n","            preserves the magnitude of the variance of the weights in the\n","            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\n","            backwards pass.\n","\n","fan_in 과 fan_out 의 차이는 가중치의 분산을 forward 때 저장하는지, backward 때 저장하는지 차이다.\n","'''\n","init.kaiming_normal_??"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZcxlI-WA63v","colab_type":"code","outputId":"9e08f822-d3ed-4324-c7a8-04e71f61dab5","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925822218,"user_tz":-540,"elapsed":3518,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["w1.mean(),w1.std()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-0.0001), tensor(0.0508))"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"a8kKSR9oA63x","colab_type":"code","outputId":"d40e87d2-ef27-495f-8cf3-91df97204685","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925822218,"user_tz":-540,"elapsed":3350,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["t.mean(),t.std()    # 위에 수식으로 구현한 결과와 거의같다."],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.5323), tensor(0.8023))"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"5SdRJFdLA631","colab_type":"code","colab":{}},"source":["import torch.nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_x12PbW5A634","colab_type":"code","outputId":"0250f961-79b5-497b-bc33-a8950cca7d02","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566925822219,"user_tz":-540,"elapsed":3004,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["print(w1.shape)\n","print(torch.nn.Linear(m,nh).weight.shape)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["torch.Size([784, 50])\n","torch.Size([50, 784])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eh_7ocOn55Gi","colab_type":"text"},"source":["직접 Tensor로 구현한 w1의 shape은 [784, 50] 인데, nn.Linear(m.nh)로 구현하면 [50, 784] 이다. \n","\n","(m = 784, nh = 50)\n","\n","왜 서로 반대의 shape을 가질까? 소스코드를 확인해보자."]},{"cell_type":"code","metadata":{"id":"oGcMpVb6A635","colab_type":"code","colab":{}},"source":["\"\"\"\n","@weak_script_method\n","    def forward(self, input):\n","        return F.linear(input, self.weight, self.bias)\n","\"\"\"\n","torch.nn.Linear.forward??"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"smOcSYm16fK5","colab_type":"text"},"source":["forward 함수는 반환값으로 F.linear 즉, torch.nn.functional.linear 을 반환한다."]},{"cell_type":"code","metadata":{"id":"PgTfa1E_A637","colab_type":"code","colab":{}},"source":["'''\n","@weak_script\n","def linear(input, weight, bias=None):\n","    # type: (Tensor, Tensor, Optional[Tensor]) -> Tensor\n","    r\"\"\"\n","    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n","\n","    Shape:\n","\n","        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n","          additional dimensions\n","        - Weight: :math:`(out\\_features, in\\_features)`\n","        - Bias: :math:`(out\\_features)`\n","        - Output: :math:`(N, *, out\\_features)`\n","    \"\"\"\n","    if input.dim() == 2 and bias is not None:\n","        # fused op is marginally faster\n","        ret = torch.addmm(bias, input, weight.t())\n","    else:\n","        output = input.matmul(weight.t())\n","        if bias is not None:\n","            output += bias\n","        ret = output\n","    return ret\n","'''\n","torch.nn.functional.linear??"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3zKL0l-7GwU","colab_type":"text"},"source":["소스코드를 잘 보면 `ret = torch.addmm(bias, input, weight.t())` 부분에서 `weight.t()` 를 통해 Transpose 하는 부분이 있다. \n","\n","Transpose를 해서 계산을 하기 때문에 `torch.nn.Linear(m,nh).weight.shape` 이 m, nh 순서가 바뀐 [50, 784] 가 된다."]},{"cell_type":"markdown","metadata":{"id":"FAZIypkQ7wgi","colab_type":"text"},"source":["### Convolution 레이어는 어떻게 초기화될까?"]},{"cell_type":"code","metadata":{"id":"zWfbuArcA639","colab_type":"code","colab":{}},"source":["'''\n","class Conv2d(_ConvNd): \n","\n","이 클래스는 _ConvNd 클래스를 상속받았다.\n","File:           /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\n","을 참조해서 _ConvNd 클래스 소스코드를 열어보자.\n","'''\n","torch.nn.Conv2d??"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaNu-pNBA64B","colab_type":"code","colab":{}},"source":["'''\n","def reset_parameters(self):\n","        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in)\n","            init.uniform_(self.bias, -bound, bound)\n","'''\n","torch.nn.modules.conv._ConvNd.reset_parameters??"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-i36rrd8In8","colab_type":"text"},"source":["Conv 또한 `init.kaiming_uniform_(self.weight, a=math.sqrt(5))` 으로 초기화 됨을 알 수 있다."]},{"cell_type":"markdown","metadata":{"id":"xO7QAQrU9Phz","colab_type":"text"},"source":["### 모델을 다시 만들자"]},{"cell_type":"code","metadata":{"id":"lw7EBKopA64D","colab_type":"code","colab":{}},"source":["# 만약에 relu를 이렇게 정의한다면...?\n","def relu(x): return x.clamp_min(0.) - 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPaCibC9A64G","colab_type":"code","outputId":"6407e271-4272-45ef-f3c7-03f5b2348739","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925833271,"user_tz":-540,"elapsed":525,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["# kaiming init / he init for relu\n","w1 = torch.randn(m,nh)*math.sqrt(2./m )\n","t1 = relu(lin(x_valid, w1, b1))\n","t1.mean(),t1.std()  # 표준편차가 1에 더 가까워지는 효과를 얻을 수 있었다.\n","                    # 강의에서 경험상 relu 에 0.5 를 빼주는게 도움이 되었다고 알려줌"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.0812), tensor(0.8520))"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"cdLEoEp8A64J","colab_type":"code","colab":{}},"source":["# 2개의 hidden layer를 지나는 모델\n","def model(xb):\n","    l1 = lin(xb, w1, b1)\n","    l2 = relu(l1)\n","    l3 = lin(l2, w2, b2)\n","    return l3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q33eeUQXA64L","colab_type":"code","outputId":"6ab11b69-eac5-4f38-c6f3-d4503b5eb901","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925837187,"user_tz":-540,"elapsed":1261,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%timeit -n 10 _=model(x_valid)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["10 loops, best of 3: 20.9 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZDyc-_OKA64O","colab_type":"code","colab":{}},"source":["assert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GXOX-6NoA64Q","colab_type":"text"},"source":["### Loss function: MSE\n","\n","손실 함수를 정의해보자. cross-entropy를 사용하지 않고, 단순화 하기 위해 일단 MSE를 사용한다. (추후에 변경)"]},{"cell_type":"code","metadata":{"id":"4VDqNQomA64R","colab_type":"code","outputId":"a852dab9-446a-4423-95da-3033f8e36d8b","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925840832,"user_tz":-540,"elapsed":668,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["model(x_valid).shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 1])"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"GD8FYu0qA64S","colab_type":"text"},"source":["모델이 반환하는 텐서의 크기가 torch.Size([10000, 1]) 이다.\n","\n","이전 강의에서 다룬 `squeeze()` 메소드를 사용해서 (,1) 형태의 shape을 제거해야 `mse`를 사용할 수 있다. "]},{"cell_type":"code","metadata":{"id":"95K-B-2t_CZb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6c2b1b31-90ac-4bef-e545-f1053ed8d5a9","executionInfo":{"status":"ok","timestamp":1566925843029,"user_tz":-540,"elapsed":558,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["model(x_valid).squeeze(-1).shape    # (,1) 이 제거됨"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"GsTU8dKSA64T","colab_type":"code","colab":{}},"source":["#export\n","def mse(output, targ): \n","    return (output.squeeze(-1) - targ).pow(2).mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"52EQbWUsA64V","colab_type":"code","colab":{}},"source":["y_train,y_valid = y_train.float(),y_valid.float()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"saHApn5bA64Y","colab_type":"code","colab":{}},"source":["preds = model(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0FP5Lq2A64b","colab_type":"code","outputId":"106c9fd9-5591-490b-942c-965363958f54","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925847500,"user_tz":-540,"elapsed":358,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["preds.shape # 모델이 예측한 값. (아직 학습은 이뤄지지 않음)"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([50000, 1])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"cgw6Vn_pA64e","colab_type":"code","outputId":"dfb0d3b8-10d2-45cf-8426-deed71b6b8ae","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566925848154,"user_tz":-540,"elapsed":553,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["mse(preds, y_train) # MSE 가 매우 크다. \n","                    # 이제 학습을 통해 MSE를 최소화 하자."],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(26.5701)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"lJyBwbaPA64j","colab_type":"text"},"source":["### Gradients and backward pass\n","\n","기울기 계산과 역전파 수행\n","\n","각각의 수식마다의 기울기 계산식을 만들자. (행렬 계산방법은 `The Matrix Calculus You Need For Deep Learning` 을 참고하자)"]},{"cell_type":"code","metadata":{"id":"00_dS9HOA64l","colab_type":"code","colab":{}},"source":["def mse_grad(inp, targ): \n","    # 이전 레이어의 출력에 대한 손실의 기울기\n","    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxiwPdV9A64m","colab_type":"code","colab":{}},"source":["def relu_grad(inp, out):\n","    # 입력 활성화함수에 대한 relu의 기울기\n","    inp.g = (inp>0).float() * out.g # relu grad: 0 or 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNrwFBn-A64o","colab_type":"code","colab":{}},"source":["def lin_grad(inp, out, w, b):\n","    # 입력에 대한 matmul의 기울기\n","    inp.g = out.g @ w.t()\n","    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n","    b.g = out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCp8hnsdA64q","colab_type":"code","colab":{}},"source":["def forward_and_backward(inp, targ):\n","    # forward pass:\n","    l1 = inp @ w1 + b1\n","    l2 = relu(l1)\n","    out = l2 @ w2 + b2\n","    # backward 에서는 사실 loss 가 필요없다. loss를 구할 필요는 없긴함(수렴하는지 확인용)\n","    loss = mse(out, targ)\n","    \n","    # backward pass:\n","    # mse -> lin2 -> relu -> lin1 순서로 거꾸로 계산 (체인룰)\n","    mse_grad(out, targ)\n","    lin_grad(l2, out, w2, b2)\n","    relu_grad(l1, l2)\n","    lin_grad(inp, l1, w1, b1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZH-Rlt3A64r","colab_type":"code","colab":{}},"source":["forward_and_backward(x_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QjGNdXmpD8QA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"4d89b842-2969-4f3b-e5b1-7f1c54199cad","executionInfo":{"status":"ok","timestamp":1566925920994,"user_tz":-540,"elapsed":581,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["w1.g, b1.g # 이런식으로 .g 에 기울기가 저장된다."],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.0052,  0.3086,  0.3542,  ...,  0.0121, -0.2450,  0.6635],\n","         [ 0.0052,  0.3086,  0.3542,  ...,  0.0121, -0.2450,  0.6635],\n","         [ 0.0052,  0.3086,  0.3542,  ...,  0.0121, -0.2450,  0.6635],\n","         ...,\n","         [ 0.0052,  0.3086,  0.3542,  ...,  0.0121, -0.2450,  0.6635],\n","         [ 0.0052,  0.3086,  0.3542,  ...,  0.0121, -0.2450,  0.6635],\n","         [ 0.0052,  0.3086,  0.3542,  ...,  0.0121, -0.2450,  0.6635]]),\n"," tensor([-0.0123, -0.7272, -0.8345,  0.0920,  0.6048,  0.1824, -0.2442,  0.0336,\n","         -0.3668,  0.5408, -0.8034,  0.2622, -0.3996,  0.3065,  0.9204,  1.5724,\n","         -0.0693,  1.0817,  0.1523,  0.2087, -0.4128, -0.2323,  1.0893, -1.2743,\n","         -0.0520, -0.3629, -0.0363,  0.1273,  0.3370,  0.2268,  0.7889,  0.3509,\n","          0.0781, -0.2372,  0.1027,  0.4583,  0.3019,  0.0180, -0.8386,  1.9626,\n","          0.3507, -0.3786, -0.3715, -0.3063,  1.0787,  0.2786, -0.0229, -0.0285,\n","          0.5773, -1.5632]))"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"PJApcY_vA64s","colab_type":"code","colab":{}},"source":["# 나중에 테스트해보기 위해서 기울기를 다 저장해두자.\n","w1g = w1.g.clone()\n","w2g = w2.g.clone()\n","b1g = b1.g.clone()\n","b2g = b2.g.clone()\n","ig  = x_train.g.clone()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50y2FKowA64u","colab_type":"text"},"source":["이제 파이토치의 autograd 를 사용해서 결과를 확인해보자.\n","\n","autograd는 결국 위에서 작성한 `forward_and_backward` 를 수행하면서 생기는 기울기를 모두 추적하는 것이다."]},{"cell_type":"code","metadata":{"id":"Dvn6d_ZlA64u","colab_type":"code","colab":{}},"source":["xt2 = x_train.clone().requires_grad_(True)\n","w12 = w1.clone().requires_grad_(True)\n","w22 = w2.clone().requires_grad_(True)\n","b12 = b1.clone().requires_grad_(True)\n","b22 = b2.clone().requires_grad_(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDNPRKY-A64w","colab_type":"code","colab":{}},"source":["def forward(inp, targ):\n","    # forward pass:\n","    l1 = inp @ w12 + b12\n","    l2 = relu(l1)\n","    out = l2 @ w22 + b22\n","    # we don't actually need the loss in backward!\n","    return mse(out, targ)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuNpnJ4JA64z","colab_type":"code","colab":{}},"source":["loss = forward(xt2, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrQYwKHdA640","colab_type":"code","colab":{}},"source":["loss.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfbIQh6nA641","colab_type":"code","colab":{}},"source":["test_near(w22.grad, w2g)\n","test_near(b22.grad, b2g)\n","test_near(w12.grad, w1g)\n","test_near(b12.grad, b1g)\n","test_near(xt2.grad, ig )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yw75tINxEvFR","colab_type":"text"},"source":["수식으로 구한 기울기와 autograd 가 구해준 기울기가 같음을 증명했다."]},{"cell_type":"markdown","metadata":{"id":"e2gF92psA642","colab_type":"text"},"source":["## Refactor model"]},{"cell_type":"markdown","metadata":{"id":"VuZfmd6fA643","colab_type":"text"},"source":["### Layers as classes\n","\n","레이어들을 각각 클래스로 만들자. \n","\n","`__call__` 은 forward, backward 는 backward 를 구현"]},{"cell_type":"code","metadata":{"id":"mWdtmumbA644","colab_type":"code","colab":{}},"source":["class Relu():\n","    def __call__(self, inp):\n","        self.inp = inp\n","        self.out = inp.clamp_min(0.)-0.5\n","        return self.out\n","    \n","    # 위에서 정의했던 수식과 똑같다.\n","    def backward(self): \n","        self.inp.g = (self.inp>0).float() * self.out.g"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3VK5IjvA645","colab_type":"code","colab":{}},"source":["class Lin():\n","    def __init__(self, w, b): \n","        self.w,self.b = w,b\n","        \n","    def __call__(self, inp):\n","        self.inp = inp\n","        self.out = inp@self.w + self.b\n","        return self.out\n","\n","    # 위에서 정의했던 수식과 똑같다.\n","    def backward(self):\n","        self.inp.g = self.out.g @ self.w.t()\n","        # Creating a giant outer product, just to sum it, is inefficient!\n","        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n","        self.b.g = self.out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0QFuKjIA647","colab_type":"code","colab":{}},"source":["class Mse():\n","    def __call__(self, inp, targ):\n","        self.inp = inp\n","        self.targ = targ\n","        self.out = (inp.squeeze() - targ).pow(2).mean()\n","        return self.out\n","        \n","    # 위에서 정의했던 수식과 똑같다.\n","    def backward(self):\n","        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrHOB7QjA648","colab_type":"code","colab":{}},"source":["class Model():\n","    def __init__(self, w1, b1, w2, b2):\n","        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]  # 사용할 Layer를 모두 넣어둠\n","        self.loss = Mse()\n","\n","    # forward    \n","    def __call__(self, x, targ):\n","        for l in self.layers: \n","            x = l(x)\n","        return self.loss(x, targ)\n","    \n","    # backward\n","    def backward(self):\n","        self.loss.backward()\n","        for l in reversed(self.layers): \n","            l.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddMEEv4iA649","colab_type":"code","colab":{}},"source":["w1.g,b1.g,w2.g,b2.g = [None]*4  # 기울기를 모두 None 으로 초기화\n","model = Model(w1, b1, w2, b2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eNX5bomA64-","colab_type":"code","outputId":"408f4d54-e559-4501-be24-81434db5e952","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566926682150,"user_tz":-540,"elapsed":800,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time loss = model(x_train, y_train)"],"execution_count":83,"outputs":[{"output_type":"stream","text":["CPU times: user 115 ms, sys: 2.9 ms, total: 118 ms\n","Wall time: 119 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lxegLmOhA65A","colab_type":"code","outputId":"828de52f-faef-4efd-95ac-ffe9b28fa55f","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566926705587,"user_tz":-540,"elapsed":7908,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time model.backward() # 시간이 많이 소요된다."],"execution_count":84,"outputs":[{"output_type":"stream","text":["CPU times: user 3.62 s, sys: 3.64 s, total: 7.26 s\n","Wall time: 7.3 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AVoaF6NrA65B","colab_type":"code","colab":{}},"source":["test_near(w2g, w2.g)\n","test_near(b2g, b2.g)\n","test_near(w1g, w1.g)\n","test_near(b1g, b1.g)\n","test_near(ig, x_train.g)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HWTQSrPcHOUl","colab_type":"text"},"source":["기존과 똑같은 결과를 반환함을 확인"]},{"cell_type":"markdown","metadata":{"id":"sXRCbxH0A65E","colab_type":"text"},"source":["### Module.forward()\n","\n","`__call__` 을 사용하지 말고, forward 를 만들어 사용하자.\n","\n","Module 클래스를 정의하고, 다른 Layer 들이 상속하게 한다."]},{"cell_type":"code","metadata":{"id":"C2p0-fusA65E","colab_type":"code","colab":{}},"source":["class Module():\n","    # __call__ 이 호출되면 self.forward 수행\n","    def __call__(self, *args):\n","        self.args = args\n","        self.out = self.forward(*args)\n","        return self.out\n","    \n","    def forward(self): raise Exception('not implemented')\n","    def backward(self): self.bwd(self.out, *self.args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jZw83HhA65F","colab_type":"code","colab":{}},"source":["class Relu(Module):\n","    def forward(self, inp): return inp.clamp_min(0.)-0.5\n","    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuBowmscA65H","colab_type":"code","colab":{}},"source":["class Lin(Module):\n","    def __init__(self, w, b): self.w,self.b = w,b\n","        \n","    def forward(self, inp): return inp@self.w + self.b\n","    \n","    def bwd(self, out, inp):\n","        inp.g = out.g @ self.w.t()\n","        # self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0) # previous\n","        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)    # 속도 향상을 위해 einsum 으로 바꿈\n","        self.b.g = out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ad3rl3ndA65I","colab_type":"code","colab":{}},"source":["class Mse(Module):\n","    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n","    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySd-uccwA65J","colab_type":"code","colab":{}},"source":["class Model():\n","    def __init__(self):\n","        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n","        self.loss = Mse()\n","        \n","    def __call__(self, x, targ):\n","        for l in self.layers: x = l(x)\n","        return self.loss(x, targ)\n","    \n","    def backward(self):\n","        self.loss.backward()\n","        for l in reversed(self.layers): l.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXxzJTFMA65L","colab_type":"code","colab":{}},"source":["w1.g,b1.g,w2.g,b2.g = [None]*4\n","model = Model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuPaQY1-A65M","colab_type":"code","outputId":"2fc4f001-72a4-45f4-fe5c-9516d62a9ba2","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566926973844,"user_tz":-540,"elapsed":582,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time loss = model(x_train, y_train)"],"execution_count":93,"outputs":[{"output_type":"stream","text":["CPU times: user 120 ms, sys: 378 µs, total: 120 ms\n","Wall time: 120 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4qQv_F49A65O","colab_type":"code","outputId":"0d608bb7-70c6-4855-e25c-1c2c94a722f4","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566926975222,"user_tz":-540,"elapsed":803,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time model.backward()  # 기존 보다 휠씬 빨라짐 (einsum)"],"execution_count":94,"outputs":[{"output_type":"stream","text":["CPU times: user 227 ms, sys: 11.4 ms, total: 238 ms\n","Wall time: 254 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0oDtRHwuA65Q","colab_type":"code","colab":{}},"source":["# 검증\n","test_near(w2g, w2.g)\n","test_near(b2g, b2.g)\n","test_near(w1g, w1.g)\n","test_near(b1g, b1.g)\n","test_near(ig, x_train.g)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2AI-0MuUA65R","colab_type":"text"},"source":["### Without einsum\n","\n","einsum 말고 Transpose를 이용한 구현"]},{"cell_type":"code","metadata":{"id":"YorZcVawA65S","colab_type":"code","colab":{}},"source":["class Lin(Module):\n","    def __init__(self, w, b): self.w,self.b = w,b\n","        \n","    def forward(self, inp): return inp@self.w + self.b\n","    \n","    def bwd(self, out, inp):\n","        inp.g = out.g @ self.w.t()\n","        # self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)  # previous\n","        # self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)                      # previous\n","        self.w.g = inp.t() @ out.g                                              # transpose 해서 계산\n","        self.b.g = out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXC6WqW8A65T","colab_type":"code","colab":{}},"source":["w1.g,b1.g,w2.g,b2.g = [None]*4\n","model = Model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWtVlwceA65U","colab_type":"code","outputId":"b0f1f385-fefc-4fad-f80b-b464f7ffe5a4","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566927077376,"user_tz":-540,"elapsed":581,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time loss = model(x_train, y_train)"],"execution_count":98,"outputs":[{"output_type":"stream","text":["CPU times: user 112 ms, sys: 2.86 ms, total: 115 ms\n","Wall time: 114 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppd_YQaeA65V","colab_type":"code","outputId":"9669ce50-147b-4219-dd82-781cb994642d","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566927078961,"user_tz":-540,"elapsed":805,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time model.backward()  # einsum을 사용하지 않아도 똑같이 빠르다."],"execution_count":99,"outputs":[{"output_type":"stream","text":["CPU times: user 224 ms, sys: 9.96 ms, total: 234 ms\n","Wall time: 235 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7SuKWephA65Y","colab_type":"code","colab":{}},"source":["# 검증\n","test_near(w2g, w2.g)\n","test_near(b2g, b2.g)\n","test_near(w1g, w1.g)\n","test_near(b1g, b1.g)\n","test_near(ig, x_train.g)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpihsfEmA65Z","colab_type":"text"},"source":["### nn.Linear and nn.Module\n","\n","파이토치에 구현된 Linear, Relu, Module 클래스를 사용하자."]},{"cell_type":"code","metadata":{"id":"9zGCA35QA65a","colab_type":"code","colab":{}},"source":["#export\n","from torch import nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MBimUZRA65b","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","    def __init__(self, n_in, nh, n_out):\n","        super().__init__()\n","        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n","        self.loss = mse\n","        \n","    def forward(self, x, targ):\n","        for l in self.layers: x = l(x)\n","        return self.loss(x.squeeze(), targ)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRFnDWMZA65c","colab_type":"code","colab":{}},"source":["model = Model(m, nh, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8vDON3fA65d","colab_type":"code","outputId":"f7f8565e-9b2f-482c-c873-40e99ee5a759","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566927344272,"user_tz":-540,"elapsed":623,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time loss = model(x_train, y_train)"],"execution_count":109,"outputs":[{"output_type":"stream","text":["CPU times: user 99.3 ms, sys: 5.09 ms, total: 104 ms\n","Wall time: 104 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8NRCvxzgA65e","colab_type":"code","outputId":"0cb579ed-0d9c-4456-e14b-dce32703b2e0","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1566927345520,"user_tz":-540,"elapsed":543,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["%time loss.backward()   # 역시 파이토치에서 구현해둔 방법이 가장 빠르다."],"execution_count":110,"outputs":[{"output_type":"stream","text":["CPU times: user 78.2 ms, sys: 4.1 ms, total: 82.3 ms\n","Wall time: 82.3 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QT2oBO6oA65g","colab_type":"text"},"source":["## Export"]},{"cell_type":"code","metadata":{"id":"bKpzHOcFA65g","colab_type":"code","outputId":"ed47c06d-b3ed-45c9-8a67-fd446c24edf3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1566927315338,"user_tz":-540,"elapsed":2244,"user":{"displayName":"이원준","photoUrl":"","userId":"05918975562379296536"}}},"source":["!./notebook2script.py 02_fully_connected.ipynb"],"execution_count":106,"outputs":[{"output_type":"stream","text":["/bin/bash: ./notebook2script.py: No such file or directory\n"],"name":"stdout"}]}]}